{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model.AlexNet import CompositeAlexNet\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.cuda as cuda\n",
    "\n",
    "from data_process.DatasetHelper import ImageDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# Functional module contains helper functions\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import random_split, ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the composite AlexNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CompositeAlexNet(loadkws=dict(map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n",
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n",
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n",
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n",
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n",
      "label: 0 with 1000 images, named as \"cloth_mask\"\n",
      "label: 1 with 1000 images, named as \"no_face_mask\"\n",
      "label: 2 with 1000 images, named as \"surgical_mask\"\n",
      "label: 3 with 1000 images, named as \"n95_mask\"\n",
      "label: 4 with 1000 images, named as \"mask_worn_incorrectly\"\n"
     ]
    }
   ],
   "source": [
    "tranform_train = T.Compose([\n",
    "  T.Resize((227,227)),\n",
    "  # T.ToPILImage(),\n",
    "  # T.ToTensor(),\n",
    "  # T.Normalize((133.7900, 122.5296, 116.1627), (78.6071, 76.6452, 77.6168)),\n",
    "])\n",
    "\n",
    "data_dir = './data/aug_1'\n",
    "\n",
    "# unzip the augmented dataset and load it\n",
    "data = ImageDataset(data_dir, transform=tranform_train)\n",
    "\n",
    "l0_data = ImageDataset(data_dir, transform=tranform_train)\n",
    "l0_data.img_labels = data.img_labels[:1000].copy()\n",
    "\n",
    "l1_data = ImageDataset(data_dir, transform=tranform_train)\n",
    "l1_data.img_labels = data.img_labels[1000:2000].copy()\n",
    "\n",
    "l2_data = ImageDataset(data_dir, transform=tranform_train)\n",
    "l2_data.img_labels = data.img_labels[2000:3000].copy()\n",
    "\n",
    "l3_data = ImageDataset(data_dir, transform=tranform_train)\n",
    "l3_data.img_labels = data.img_labels[3000:4000].copy()\n",
    "\n",
    "l4_data = ImageDataset(data_dir, transform=tranform_train)\n",
    "l4_data.img_labels = data.img_labels[4000:5000].copy()\n",
    "\n",
    "d1, d2, d3, d4, d5, test_data = torch.utils.data.random_split(\n",
    "    l0_data, [180, 180, 180, 180, 180, 100],\n",
    "    generator=torch.Generator().manual_seed(123)\n",
    ")\n",
    "\n",
    "for data in l1_data, l2_data, l3_data, l4_data:\n",
    "  new_d1, new_d2, new_d3, new_d4, new_d5, new_test_data = torch.utils.data.random_split(\n",
    "    data, [180, 180, 180, 180, 180, 100],\n",
    "    generator=torch.Generator().manual_seed(123)\n",
    "  )\n",
    "  d1 = ConcatDataset((d1, new_d1))\n",
    "  d2 = ConcatDataset((d2, new_d2))\n",
    "  d3 = ConcatDataset((d3, new_d3))\n",
    "  d4 = ConcatDataset((d4, new_d4))\n",
    "  d5 = ConcatDataset((d5, new_d5))\n",
    "  test_data = ConcatDataset((test_data, new_test_data))\n",
    "\n",
    "batch_size = 40\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.2897,  -1.2827,  -4.0100,  -4.7228,  19.8254],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.994,\n",
       " 0.9940000000000001,\n",
       " 0.994098233352747,\n",
       " 0.9939995499587461,\n",
       " array([[100,   1,   0,   1,   0],\n",
       "        [  0,  99,   0,   0,   0],\n",
       "        [  0,   0, 100,   1,   0],\n",
       "        [  0,   0,   0,  98,   0],\n",
       "        [  0,   0,   0,   0, 100]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluation\n",
    "\n",
    "# example of how to translate my nets output(5 channels) into one label\n",
    "def output_to_label(output):\n",
    "  rs = 0\n",
    "  for i in range(5):\n",
    "    if output[i] > output[rs]:\n",
    "      rs = i\n",
    "  return rs\n",
    "\n",
    "evaluation.evaluate(\n",
    "  test_loader, \n",
    "  predict_fn=lambda x: net(x.float()),    # example for how my net predicts the output\n",
    "  output_label_match_fn=output_to_label\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75dabb51cdb480bc6facf2c981ec85f83c5f38a839d849fc6b0b7624b07b4316"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('comp6721')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
