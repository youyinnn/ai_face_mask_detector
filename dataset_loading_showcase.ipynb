{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic of gender:\n",
      "male 2070\n",
      "female 2930\n",
      "statistic of race group:\n",
      "caas 3713\n",
      "afar 1287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_process.DatasetHelper import label_map\n",
    "from data_process.DatasetHelper import ImageDataset\n",
    "\n",
    "# unzip the augmented dataset and load it\n",
    "data = ImageDataset('./data/aug_2')\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data.float(), dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean((data.float())**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# print(get_mean_and_std(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_rand(img_data):\n",
    "    figure = plt.figure(figsize=(18, 14))\n",
    "    cols, rows = 5, 5\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(img_data), size=(1,)).item()\n",
    "        img, label = img_data[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(label_map[label])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    \n",
    "show_image_rand(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 = torch.utils.data.random_split(data, [4000, 1000], generator=torch.Generator().manual_seed(0))\n",
    "# s1, s2 = torch.utils.data.random_split(data, [4000, 1000], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "def show_one(dataset, i=0):\n",
    "    img, label = dataset[i]\n",
    "    plt.title(label_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    \n",
    "show_one(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s1), len(s2))\n",
    "\n",
    "show_image_rand(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, test_data = torch.utils.data.random_split(data, [900, 900, 900, 900, 900, 500], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label(ds):\n",
    "  for d in ds:\n",
    "    l_map = {}\n",
    "    for item in d:\n",
    "      l = item[1]\n",
    "      if l_map.get(l) == None:\n",
    "        l_map[l] = 0\n",
    "      l_map[l] += 1\n",
    "    print(l_map)\n",
    "    \n",
    "check_label([s1, s2, s3, s4, s5, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s1), len(s2), len(s3), len(s4), len(s5), len(test_data))\n",
    "\n",
    "show_one(s2, i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_ds = torch.utils.data.ConcatDataset((s2, s3, s4, s1, s5))\n",
    "\n",
    "show_one(chain_ds, i=901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the augmented dataset and load it\n",
    "data = ImageDataset('./data/aug_2')\n",
    "\n",
    "l0_data = ImageDataset('./data/aug_2')\n",
    "l0_data.img_labels = data.img_labels[:1000].copy()\n",
    "\n",
    "check_label([l0_data])\n",
    "\n",
    "l1_data = ImageDataset('./data/aug_2')\n",
    "l1_data.img_labels = data.img_labels[1000:2000].copy()\n",
    "\n",
    "check_label([l1_data])\n",
    "\n",
    "l2_data = ImageDataset('./data/aug_2')\n",
    "l2_data.img_labels = data.img_labels[2000:3000].copy()\n",
    "\n",
    "check_label([l2_data])\n",
    "\n",
    "l3_data = ImageDataset('./data/aug_2')\n",
    "l3_data.img_labels = data.img_labels[3000:4000].copy()\n",
    "\n",
    "check_label([l3_data])\n",
    "\n",
    "l4_data = ImageDataset('./data/aug_2')\n",
    "l4_data.img_labels = data.img_labels[4000:5000].copy()\n",
    "\n",
    "check_label([l4_data])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75dabb51cdb480bc6facf2c981ec85f83c5f38a839d849fc6b0b7624b07b4316"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('comp6721')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
